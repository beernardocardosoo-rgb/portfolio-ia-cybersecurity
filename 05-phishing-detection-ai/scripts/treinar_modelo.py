import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import joblib

def carregar_dataset(caminho: str) -> pd.DataFrame:
    """
    Carrega o dataset com features jÃ¡ extraÃ­das.
    """
    if not os.path.exists(caminho):
        raise FileNotFoundError(f"âŒ Arquivo nÃ£o encontrado: {caminho}")

    print(f"ğŸ“¥ Carregando dataset com features de: {caminho}")
    df = pd.read_csv(caminho)
    print(f"âœ… Dataset carregado com {len(df):,} linhas e {len(df.columns)} colunas.")
    return df

def preparar_dados(df: pd.DataFrame):
    """
    Separa features (X) e label (y).
    """
    # Features: todas as colunas exceto 'url', 'label_text', 'label'
    features = [col for col in df.columns if col not in ['url', 'label_text', 'label']]

    X = df[features].astype(float)  # Garante que tudo Ã© numÃ©rico
    y = df['label']                  # 0 = good, 1 = bad

    print(f"\nğŸ“Š Features usadas para treino: {features}")
    print(f"   Total de {len(features)} features.")

    return X, y

def treinar_e_avaliar(X, y):
    """
    Divide em treino/teste, treina RandomForest e avalia.
    """
    print("\nSplitOptions train_test_split...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    print(f"   {len(X_train):,} amostras para treino")
    print(f"   {len(X_test):,} amostras para teste")

    # Instancia e treina o modelo
    print("\nğŸŒ² Treinando RandomForestClassifier...")
    modelo = RandomForestClassifier(
        n_estimators=100,      # nÃºmero de Ã¡rvores
        max_depth=10,          # profundidade mÃ¡xima (evita overfit)
        random_state=42,
        n_jobs=-1              # usa todos os nÃºcleos do processador
    )
    modelo.fit(X_train, y_train)

    # AvaliaÃ§Ã£o
    print("\nğŸ“ˆ Avaliando modelo...")
    y_pred = modelo.predict(X_test)

    print(f"\nâœ… Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print("\nğŸ“‹ Classification Report:")
    print(classification_report(y_test, y_pred, target_names=['LegÃ­tima (good)', 'Phishing (bad)']))

    print("\nğŸ“Š Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))

    return modelo

def salvar_modelo(modelo, caminho_saida: str):
    """
    Salva o modelo treinado em disco.
    """
    pasta = os.path.dirname(caminho_saida)
    if pasta and not os.path.exists(pasta):
        os.makedirs(pasta, exist_ok=True)

    joblib.dump(modelo, caminho_saida)
    print(f"\nğŸ’¾ Modelo salvo em: {caminho_saida}")
    print(f"   Tamanho do arquivo: {os.path.getsize(caminho_saida) / 1024:.2f} KB")

def main():
    """
    Pipeline completo de treino.
    """
    print("=" * 70)
    print("ğŸŒ² TREINAMENTO DE MODELO DE DETECÃ‡ÃƒO DE PHISHING")
    print("=" * 70)

    caminho_entrada = os.path.join("dados", "urls_com_features.csv")
    caminho_modelo = os.path.join("modelos", "modelo_phishing.pkl")

    # 1. Carregar dataset com features
    df = carregar_dataset(caminho_entrada)

    # 2. Preparar dados
    X, y = preparar_dados(df)

    # 3. Treinar e avaliar
    modelo = treinar_e_avaliar(X, y)

    # 4. Salvar modelo
    salvar_modelo(modelo, caminho_modelo)

    print("\n" + "=" * 70)
    print("âœ… TREINAMENTO CONCLUÃDO COM SUCESSO!")
    print("=" * 70)
    

if __name__ == "__main__":
    main()
