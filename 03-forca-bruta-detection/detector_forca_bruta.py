import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

print("=" * 70)
print("ğŸ” DETECTOR DE FORÃ‡A BRUTA COM MACHINE LEARNING")
print("=" * 70)

# ========== CARREGAR DADOS ==========
print("\nğŸ“‚ Carregando dataset...")
df = pd.read_csv('dados/logins_gerados.csv')
print(f"âœ… Dataset carregado: {len(df)} eventos")

# ========== PRÃ‰-PROCESSAMENTO ==========
print("\nğŸ”§ PrÃ©-processando dados...")

# Converter timestamp para datetime
df['timestamp'] = pd.to_datetime(df['timestamp'])

# Extrair features temporais
df['hora'] = df['timestamp'].dt.hour
df['dia_semana'] = df['timestamp'].dt.dayofweek

# Codificar variÃ¡veis categÃ³ricas
df['ip_encoded'] = pd.factorize(df['ip'])[0]
df['usuario_encoded'] = pd.factorize(df['usuario'])[0]
df['localizacao_encoded'] = pd.factorize(df['localizacao'])[0]

# Features para o modelo
features = ['tentativas_intervalo', 'origem_confiavel', 'sucesso', 
            'hora', 'dia_semana', 'ip_encoded', 'usuario_encoded', 
            'localizacao_encoded']

X = df[features].copy()

# Normalizar features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print(f"âœ… Features preparadas: {len(features)} variÃ¡veis")

# ========== TREINAR MODELO ==========
print("\nğŸ¤– Treinando modelo Isolation Forest...")

# Isolation Forest para detecÃ§Ã£o de anomalias
modelo = IsolationForest(
    contamination=0.05,  # 5% sÃ£o anomalias (ataques)
    random_state=42,
    n_estimators=100
)

# Treinar
predicoes = modelo.fit_predict(X_scaled)
scores = modelo.score_samples(X_scaled)

# Adicionar ao dataframe
df['anomalia'] = predicoes  # -1 = anomalia, 1 = normal
df['anomalia_score'] = scores

print(f"âœ… Modelo treinado com sucesso!")

# ========== ANÃLISE DE RESULTADOS ==========
print("\nğŸ“Š RESULTADOS DA DETECÃ‡ÃƒO:")
print("-" * 70)

total_anomalias = (df['anomalia'] == -1).sum()
total_normais = (df['anomalia'] == 1).sum()

print(f"ğŸ” Eventos normais: {total_normais} ({100*total_normais/len(df):.1f}%)")
print(f"ğŸš¨ Eventos anÃ´malos (ataques): {total_anomalias} ({100*total_anomalias/len(df):.1f}%)")

# ========== IDENTIFICAR IPS ATACANTES ==========
print("\nğŸ•µï¸ IPS SUSPEITOS DETECTADOS:")
print("-" * 70)

ips_suspeitos = df[df['anomalia'] == -1]['ip'].value_counts().head(10)

for ip, count in ips_suspeitos.items():
    localizacao = df[df['ip'] == ip]['localizacao'].iloc[0]
    confianca = (count / total_anomalias) * 100
    print(f"   IP: {ip}")
    print(f"   Tentativas anÃ´malas: {count}")
    print(f"   LocalizaÃ§Ã£o: {localizacao}")
    print(f"   ConfianÃ§a: {confianca:.1f}%")
    print()

# ========== GERAR ALERTAS ==========
print("\nâš ï¸ GERANDO ALERTAS...")

alertas = []

for ip in ips_suspeitos.head(5).index:
    eventos_ip = df[df['ip'] == ip]
    eventos_ataque = eventos_ip[eventos_ip['anomalia'] == -1]

    usuarios_alvo = eventos_ataque['usuario'].unique()
    localizacao = eventos_ataque['localizacao'].iloc[0]
    tentativas = eventos_ataque['tentativas_intervalo'].mean()

    alerta = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸš¨ ALERTA DE SEGURANÃ‡A ğŸš¨                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

IP ATACANTE: {ip}
LOCALIZAÃ‡ÃƒO: {localizacao}
TENTATIVAS DETECTADAS: {len(eventos_ataque)}
MÃ‰DIA DE TENTATIVAS/INTERVALO: {tentativas:.1f}

USUÃRIOS ALVO:
{', '.join(usuarios_alvo)}

CONFIANÃ‡A DA DETECÃ‡ÃƒO: {(len(eventos_ataque)/total_anomalias)*100:.1f}%

RECOMENDAÃ‡ÃƒO: â›” BLOQUEAR IP IMEDIATAMENTE

Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    alertas.append(alerta)

# Salvar alertas em arquivo
with open('resultados/alertas.txt', 'w', encoding='utf-8') as f:
    f.write("ğŸ” RELATÃ“RIO DE ALERTAS DE FORÃ‡A BRUTA\n")
    f.write(f"Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write("=" * 70 + "\n\n")
    for alerta in alertas:
        f.write(alerta)

print(f"âœ… {len(alertas)} alertas gerados e salvos em: resultados/alertas.txt")

# ========== GERAR RELATÃ“RIO DETALHADO ==========
print("\nğŸ“‹ GERANDO RELATÃ“RIO DETALHADO...")

relatorio = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         RELATÃ“RIO DE DETECÃ‡ÃƒO DE FORÃ‡A BRUTA                  â•‘
â•‘                   Machine Learning Analysis                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATA DO RELATÃ“RIO: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š ESTATÃSTICAS GERAIS:

   â€¢ Total de eventos analisados: {len(df):,}
   â€¢ PerÃ­odo: {df['timestamp'].min()} atÃ© {df['timestamp'].max()}
   â€¢ IPs Ãºnicos: {df['ip'].nunique()}
   â€¢ UsuÃ¡rios Ãºnicos: {df['usuario'].nunique()}
   â€¢ LocalizaÃ§Ãµes: {df['localizacao'].nunique()}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš¨ DETECÃ‡ÃƒO DE ATAQUES:

   â€¢ Eventos normais: {total_normais} ({100*total_normais/len(df):.2f}%)
   â€¢ Eventos anÃ´malos: {total_anomalias} ({100*total_anomalias/len(df):.2f}%)
   â€¢ Taxa de detecÃ§Ã£o: {(total_anomalias/len(df))*100:.2f}%

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ” TOP 10 IPS MAIS SUSPEITOS:

"""

for idx, (ip, count) in enumerate(ips_suspeitos.head(10).items(), 1):
    localizacao = df[df['ip'] == ip]['localizacao'].iloc[0]
    risco = "ğŸ”´ CRÃTICO" if count > 50 else "ğŸŸ  ALTO" if count > 20 else "ğŸŸ¡ MÃ‰DIO"
    relatorio += f"\n   {idx}. IP: {ip} | Tentativas: {count} | {risco} | LocalizaÃ§Ã£o: {localizacao}"

relatorio += f"""

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… EVENTOS LEGÃTIMOS:

   â€¢ Taxa de sucesso: {(df[df['anomalia']==1]['sucesso'].sum() / total_normais * 100):.2f}%
   â€¢ Origem confiÃ¡vel: {(df[df['anomalia']==1]['origem_confiavel'].sum() / total_normais * 100):.2f}%

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¤– MODELO UTILIZADO:

   â€¢ Algoritmo: Isolation Forest
   â€¢ ContaminaÃ§Ã£o esperada: 5%
   â€¢ Estimadores: 100
   â€¢ Seed: 42 (reprodutÃ­vel)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ RECOMENDAÃ‡Ã•ES:

   1. â›” Bloquear imediatamente os IPs crÃ­ticos
   2. ğŸ” Implementar rate limiting (mÃ¡x 5 tentativas/minuto)
   3. ğŸ“§ Notificar usuÃ¡rios sobre tentativas de acesso
   4. ğŸ” Investigar padrÃµes de ataque lento (mais sofisticados)
   5. ğŸ“Š Monitorar continuamente com este modelo

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RelatÃ³rio gerado automaticamente pelo sistema de detecÃ§Ã£o de forÃ§a bruta.
"""

with open('resultados/relatorio.txt', 'w', encoding='utf-8') as f:
    f.write(relatorio)

print("âœ… RelatÃ³rio detalhado salvo em: resultados/relatorio.txt")

# ========== SALVAR MODELO ==========
print("\nğŸ’¾ Salvando modelo treinado...")
joblib.dump(modelo, 'modelos/modelo_deteccao.pkl')
joblib.dump(scaler, 'modelos/scaler.pkl')
print("âœ… Modelo salvo em: modelos/modelo_deteccao.pkl")

# ========== GERAR GRÃFICOS ==========
print("\nğŸ“ˆ Gerando visualizaÃ§Ãµes...")

# Configurar estilo
sns.set_style("darkgrid")
plt.rcParams['figure.figsize'] = (14, 10)

# GrÃ¡fico 1: DistribuiÃ§Ã£o de anomalias
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# GrÃ¡fico 1.1: Pie chart de anomalias
cores = ['#2ecc71', '#e74c3c']
axes[0, 0].pie([total_normais, total_anomalias], 
               labels=['Normal', 'AnÃ´malo'], 
               autopct='%1.1f%%',
               colors=cores,
               startangle=90,
               textprops={'fontsize': 12, 'weight': 'bold'})
axes[0, 0].set_title('DistribuiÃ§Ã£o de Eventos\n(Normal vs AnÃ´malo)', fontsize=14, weight='bold')

# GrÃ¡fico 1.2: Top 10 IPs suspeitos
ips_suspeitos.head(10).plot(kind='barh', ax=axes[0, 1], color='#e74c3c')
axes[0, 1].set_title('Top 10 IPs Mais Suspeitos', fontsize=14, weight='bold')
axes[0, 1].set_xlabel('NÃºmero de Tentativas AnÃ´malas', fontsize=11)
axes[0, 1].invert_yaxis()

# GrÃ¡fico 1.3: Anomalias por hora do dia
anomalias_hora = df[df['anomalia'] == -1]['hora'].value_counts().sort_index()
axes[1, 0].bar(anomalias_hora.index, anomalias_hora.values, color='#e74c3c', alpha=0.7)
axes[1, 0].set_title('Ataques por Hora do Dia', fontsize=14, weight='bold')
axes[1, 0].set_xlabel('Hora do Dia', fontsize=11)
axes[1, 0].set_ylabel('Quantidade de Ataques', fontsize=11)

# GrÃ¡fico 1.4: Score de anomalia
axes[1, 1].hist(df[df['anomalia'] == 1]['anomalia_score'], bins=50, alpha=0.7, label='Normal', color='#2ecc71')
axes[1, 1].hist(df[df['anomalia'] == -1]['anomalia_score'], bins=50, alpha=0.7, label='AnÃ´malo', color='#e74c3c')
axes[1, 1].set_title('DistribuiÃ§Ã£o de Scores de Anomalia', fontsize=14, weight='bold')
axes[1, 1].set_xlabel('Score de Anomalia', fontsize=11)
axes[1, 1].set_ylabel('FrequÃªncia', fontsize=11)
axes[1, 1].legend()

plt.tight_layout()
plt.savefig('resultados/analise_deteccao.png', dpi=300, bbox_inches='tight')
print("âœ… GrÃ¡fico salvo em: resultados/analise_deteccao.png")

# GrÃ¡fico 2: Matriz de confusÃ£o visual
fig, ax = plt.subplots(figsize=(10, 6))

tentativas_por_ip = df.groupby('ip')['tentativas_intervalo'].mean()
anomalias_por_ip = df[df['anomalia'] == -1].groupby('ip').size()

dados_plot = pd.DataFrame({
    'Tentativas MÃ©dias': tentativas_por_ip,
    'Anomalias Detectadas': anomalias_por_ip
}).fillna(0).head(15)

dados_plot.plot(kind='barh', ax=ax, color=['#3498db', '#e74c3c'])
ax.set_title('AnÃ¡lise de Tentativas vs Anomalias por IP', fontsize=14, weight='bold')
ax.set_xlabel('Quantidade', fontsize=11)
plt.tight_layout()
plt.savefig('resultados/analise_ips.png', dpi=300, bbox_inches='tight')
print("âœ… GrÃ¡fico salvo em: resultados/analise_ips.png")

# ========== RESUMO FINAL ==========
print("\n" + "=" * 70)
print("âœ… ANÃLISE CONCLUÃDA COM SUCESSO!")
print("=" * 70)
print(f"\nğŸ“ Arquivos gerados:")
print(f"   âœ… dados/logins_gerados.csv")
print(f"   âœ… modelos/modelo_deteccao.pkl")
print(f"   âœ… modelos/scaler.pkl")
print(f"   âœ… resultados/alertas.txt")
print(f"   âœ… resultados/relatorio.txt")
print(f"   âœ… resultados/analise_deteccao.png")
print(f"   âœ… resultados/analise_ips.png")
print(f"\nğŸ¯ PrÃ³ximos passos:")
print(f"   1. Revisar os alertas em: resultados/alertas.txt")
print(f"   2. Analisar o relatÃ³rio em: resultados/relatorio.txt")
print(f"   3. Visualizar os grÃ¡ficos em: resultados/")
print(f"   4. Usar o modelo salvo para novas prediÃ§Ãµes")
print("\n" + "=" * 70)
